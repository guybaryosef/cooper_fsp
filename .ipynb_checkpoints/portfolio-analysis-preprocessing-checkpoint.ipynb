{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f87d33c50d030934a026dedefd83a0b789a57794"
   },
   "source": [
    "## ECE 478 Financial Signal Processing\n",
    "## Pset1: Portoflio Analysis\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "We will begin with reading the Farma and French 48 benchmark dataset, which provides returns for 48 composite portfolios, each of which is made up of stocks from a different sector in the economy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "daily_data = pd.read_csv(\"../input/48_Industry_Portfolios_daily.CSV\", low_memory=False)\n",
    "monthly_data = pd.read_csv(\"../input/48_Industry_Portfolios_Wout_Div.csv\")\n",
    "\n",
    "daily_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "560becf72470c66e16db479fef30ff041c685e17"
   },
   "source": [
    "We see returns for 48 sectors(Argic, Food, etc.) as well as an unamed first column which gives us the date in a [Year][Month][Day] format.\n",
    "\n",
    "Although we can't see it above, the data  actually appears twice, once for average value weighted returns and again for equally weighted returns. We will be interested in the equally weighted returns data between the years 2000 - 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb33c4d77e61fd7ce7fa792096b818fe7f72de28"
   },
   "outputs": [],
   "source": [
    "daily_data.rename(columns={'Unnamed: 0': 'Date'}, inplace=True)\n",
    "tmp = daily_data.index[daily_data['Date'] == '19260701'].tolist()\n",
    "equally_weighted_daily_data = daily_data.loc[24267:]\n",
    "\n",
    "equally_weighted_daily_data.set_index('Date', inplace=True) # set the date as the index\n",
    "equally_weighted_daily_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "00381463aa3fea143fed22fbaa86e67c0df3107e"
   },
   "source": [
    "We now seperate each year into its own dataset. Note that the year doesn't have to start on Jan 1st and end on Dec 31st, due to the possibility of these dates landing on weekends. In fact, we will say that there are 251 work days in a full year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef6bc20212ad65620fe85673a5832c02a4e1f474"
   },
   "outputs": [],
   "source": [
    "def split_into_years(original_data, beg_year = 2000, amount_years = 17):\n",
    "    list_of_new_datasets = []\n",
    "    for i in range(amount_years):\n",
    "        # due to weekends, need to make sure we start with correct index\n",
    "        start_date = (beg_year+i)*(10**4) + 101\n",
    "        while (str(start_date) not in original_data.index):\n",
    "            start_date += 1\n",
    "\n",
    "        end_date = (beg_year+i)*(10**4) + 1231\n",
    "        while (str(end_date) not in original_data.index):\n",
    "            end_date -= 1\n",
    "\n",
    "        list_of_new_datasets.append(original_data.loc[str(start_date):str(end_date)])\n",
    "    return list_of_new_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9160d6240e643c5ba3cd6d8294089890f6174681"
   },
   "outputs": [],
   "source": [
    "daily_return_by_year = split_into_years(equally_weighted_daily_data) # list of our new datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a04858a4a6274afdd6014e9312b132431cd0134e"
   },
   "source": [
    "We will now deal with the missing data, which the dataset mentions takes the value -99.9 or -999. Just in case, we will search for empty cells also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b35f7a6b4d27dea229ad12e8d8c3769e1aa49bfa"
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(daily_return_by_year):\n",
    "    print('Dataset of:', i+2000, end=' --- ')\n",
    "    for col in data:\n",
    "        count = (data[col] == ' -99.99').sum() + (data[col] == ' -999').sum() + data[col].isnull().sum()\n",
    "        if count > 0:\n",
    "            print(col + ':', count, end=\"; \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94001cb8c2eedf891fcef8aa674792b6537b85b3"
   },
   "source": [
    "Seems that we are okay on the missing data for now. To finish the preprocessing of the benchmark dataset, let us store each new dataset in a different file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59786d27948b512ce0325914e4d1784287e5152a"
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(daily_return_by_year):\n",
    "    data.to_csv('48_IP_eq_w_daily_returns_' + str(i+2000) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4abd4b62ef844a95c8015195f9135b7d96f1362"
   },
   "source": [
    "We will now move on to the S&P500 returns and USD LIBOR over these same years, making sure to normalize the time scales to daily. Note that we are approximating this approximation by including weekeds in our count, while recognizing that there are no daily returns on those days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eac91a1a0c9e1b322daee6dc7d4590daa8734d42"
   },
   "outputs": [],
   "source": [
    "sp_daily = pd.read_csv(\"../input/dailySP500.CSV\")\n",
    "sp_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c425aa630bc72b8d4c04f6f122c600a2f6fb5ab2"
   },
   "outputs": [],
   "source": [
    "print('Values to impute in Open:', sp_daily['Open'].isnull().sum())\n",
    "print('Values to impute in Adj Close:', sp_daily['Adj Close'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e9535141466667c85d32d47f6a0b01af1734f3e4"
   },
   "source": [
    "Our data is already clean, so let us move on to finding the daily returns with the formula:\n",
    "$$ Daily \\ \\ Return = \\frac{(Adj\\ \\ Close) - (Open)}{Open} $$\n",
    "and then proceed to split up these returns into individual years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76b5f142c0f3809e3e365c7759913d24feedcc12"
   },
   "outputs": [],
   "source": [
    "temp_sp_ID =  [ i.replace('-', '') for i in sp_daily['Date'] ]\n",
    "temp_sp_returns = 100 * (sp_daily['Adj Close'] - sp_daily['Open'] ) / sp_daily['Open']\n",
    "\n",
    "sp_returns = pd.DataFrame({'Date':  temp_sp_ID, 'Return': temp_sp_returns })\n",
    "sp_returns.set_index('Date', inplace=True)\n",
    "\n",
    "sp_returns_by_year = split_into_years(sp_returns)\n",
    "\n",
    "for i, data in enumerate(sp_returns_by_year):\n",
    "    data.to_csv('SP_daily_returns_' + str(i+2000) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "651a1aabf079cf1a91478f04c2f27aeefd104be7"
   },
   "source": [
    "For the USD LIBOR, we will first format the date identically to our benchmark and S&P500 returns and then we will convert the 3 month dollar LIBOR into an effective daily rate using the equation:\n",
    "$$ R =  100 \\big[ (1+ \\frac{R_m}{100})^{1/N} - 1 \\big] $$\n",
    "\n",
    "where $R$ is the daily interest rate, $m$  is the amount of times daily interest will be compounded per 3 month period, and $R_m$ is the 3 month interest rate.\n",
    "\n",
    "Assuming a 260 day work year, we can say that there there are $\\frac{251}{4} = 62$ work days per 3-month period, and so in our case $ m = 62$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81b990cc1fbafe17034dd398e0d9eaa6214edda9"
   },
   "outputs": [],
   "source": [
    "libor_daily = pd.read_csv(\"../input/LIBOR USD.csv\")\n",
    "libor_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "439c9ed7ccd90b83d6745b7d00f257a8dffd6a15"
   },
   "outputs": [],
   "source": [
    "temp_id = []\n",
    "for i in libor_daily['Date']:\n",
    "    temp = i.split('.')\n",
    "    temp_id.append(temp[2] + temp[1] + temp[0])\n",
    "\n",
    "libor_daily['Date'] = temp_id\n",
    "libor_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5fad3ab07b9151933c95642728068574d138ec6c"
   },
   "outputs": [],
   "source": [
    "print('Values to impute in 3M column:', libor_daily['3M'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "746b37bcbe20938033cbf18e34a9c5ae18c352e6"
   },
   "outputs": [],
   "source": [
    "m = 62\n",
    "\n",
    "temp_daily_rate = [100*( (1 + i/100)**(1/m) -1) for i in libor_daily['3M'] ]\n",
    "\n",
    "libor_intr = pd.DataFrame({ 'Date': libor_daily['Date'], 'Effective Daily Interest': temp_daily_rate })\n",
    "libor_intr.set_index('Date', inplace=True)\n",
    "\n",
    "libor_intr_by_year = split_into_years(libor_intr)\n",
    "\n",
    "for i, data in enumerate(libor_intr_by_year):\n",
    "    data.to_csv('LIBOR_daily_interest_' + str(i+2000) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f51aaa15895cadcfa4c20848718ee0adaefd7e7"
   },
   "source": [
    "and thats it! The actual analysis of this data is conducted [here](https://www.kaggle.com/guybaryosef/portfolio-assesment)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
